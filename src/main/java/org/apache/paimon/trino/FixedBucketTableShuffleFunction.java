/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.paimon.trino;

import org.apache.paimon.CoreOptions;
import org.apache.paimon.codegen.CodeGenUtils;
import org.apache.paimon.codegen.Projection;
import org.apache.paimon.data.BinaryRow;
import org.apache.paimon.schema.TableSchema;
import org.apache.paimon.table.sink.KeyAndBucketExtractor;
import org.apache.paimon.types.RowKind;

import io.trino.spi.Page;
import io.trino.spi.block.Block;
import io.trino.spi.block.RowBlock;
import io.trino.spi.connector.BucketFunction;
import io.trino.spi.type.RowType;
import io.trino.spi.type.Type;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.util.List;

/** Trino {@link BucketFunction}. */
public class FixedBucketTableShuffleFunction implements BucketFunction {

    private final int workerCount;
    private final int bucketCount;
    private final boolean isRowId;
    private final ThreadLocal<Projection> projectionContext;
    private final TableSchema schema;
    private final List<String> bucketKeys; // ğŸ”§ æ”¹ä¸ºé€šç”¨çš„ bucketKeys

    public FixedBucketTableShuffleFunction(
            List<Type> partitionChannelTypes,
            TrinoPartitioningHandle partitioningHandle,
            int workerCount) {

        this.schema = partitioningHandle.getOriginalSchema();

        // ğŸ”§ å…³é”®ä¿®æ”¹ï¼šæ ¹æ®æ˜¯å¦åˆ†åŒºè¡¨é€‰æ‹©ä¸åŒçš„ keys
        List<String> partitionKeys = schema.partitionKeys();
        if (!partitionKeys.isEmpty()) {
            // åˆ†åŒºè¡¨ï¼šä½¿ç”¨ partition keys
            this.bucketKeys = partitionKeys;
            this.projectionContext =
                    ThreadLocal.withInitial(
                            () ->
                                    CodeGenUtils.newProjection(
                                            schema.logicalPartitionType(), bucketKeys));
        } else {
            // éåˆ†åŒºè¡¨ï¼šä½¿ç”¨ primary keys
            this.bucketKeys = schema.primaryKeys();
            this.projectionContext =
                    ThreadLocal.withInitial(
                            () -> CodeGenUtils.newProjection(schema.logicalRowType(), bucketKeys));
        }

        this.bucketCount = new CoreOptions(schema.options()).bucket();
        this.workerCount = workerCount;
        this.isRowId =
                partitionChannelTypes.size() == 1
                        && partitionChannelTypes.get(0) instanceof RowType;
    }

    @Override
    public int getBucket(Page page, int position) {
        Page processedPage = page;

        // å¤„ç† RowBlock çš„æƒ…å†µ
        if (isRowId) {
            RowBlock rowBlock = (RowBlock) page.getBlock(0);
            try {
                Method method = RowBlock.class.getDeclaredMethod("getRawFieldBlocks");
                method.setAccessible(true);
                Block[] rawBlocks = (Block[]) method.invoke(rowBlock);
                processedPage = new Page(rowBlock.getPositionCount(), rawBlocks);
            } catch (NoSuchMethodException | InvocationTargetException | IllegalAccessException e) {
                throw new RuntimeException("Failed to extract raw field blocks from RowBlock", e);
            }
        }

        // ğŸ”§ ä¿®æ”¹éªŒè¯é€»è¾‘ï¼šéªŒè¯ bucketKeys æ•°é‡
        int expectedBlockCount = bucketKeys.size();
        int actualBlockCount = processedPage.getChannelCount();

        if (actualBlockCount != expectedBlockCount) {
            throw new IllegalStateException(
                    String.format(
                            "Page block count mismatch: expected %d (bucket keys), but got %d. "
                                    + "Bucket keys: %s, Partition keys: %s, Primary keys: %s, Schema fields: %s",
                            expectedBlockCount,
                            actualBlockCount,
                            bucketKeys,
                            schema.partitionKeys(),
                            schema.primaryKeys(),
                            schema.fieldNames()));
        }

        // ä½¿ç”¨ processedPage åˆ›å»º TrinoRow
        TrinoRow trinoRow =
                new TrinoRow(processedPage.getSingleValuePage(position), RowKind.INSERT);

        // ğŸ”§ ä¿®æ”¹é”™è¯¯ä¿¡æ¯ï¼šæ˜¾ç¤º bucketKeys ç›¸å…³ä¿¡æ¯
        BinaryRow pk;
        try {
            pk = projectionContext.get().apply(trinoRow);
        } catch (IndexOutOfBoundsException e) {
            throw new RuntimeException(
                    String.format(
                            "Failed to extract bucket keys from row. "
                                    + "Row field count: %d, Bucket keys: %s, "
                                    + "Page block count: %d, Position: %d",
                            trinoRow.getFieldCount(),
                            bucketKeys,
                            processedPage.getChannelCount(),
                            position),
                    e);
        }

        int bucket =
                KeyAndBucketExtractor.bucket(
                        KeyAndBucketExtractor.bucketKeyHashCode(pk), bucketCount);
        return bucket % workerCount;
    }
}
